{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu\n",
    "from io import open\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = conllu.parse_incr(open(\"pt_gsd-ud-train.conllu\",'r',encoding = \"utf-8\")) # парсим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentence(tokenlist):\n",
    "    sentence = [[\"*\",\"*\"]] + [[\"*\",\"*\"]]\n",
    "    for i in range(len(tokenlist)):\n",
    "        sentence += [[tokenlist[i][\"lemma\"], tokenlist[i][\"upostag\"]]]\n",
    "    sentence += [[\"STOP\",\"STOP\"]]\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = {} \n",
    "bigrams = {} \n",
    "unigrams = {} \n",
    "tagWords = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokenlist in data_train:\n",
    "    sentence = getSentence(tokenlist)\n",
    "    # считаем триграммы\n",
    "    for i in range(len(sentence)-2):  \n",
    "        count = trigrams.get( (sentence[i][1], sentence[i+1][1], sentence[i+2][1]), 0)\n",
    "        trigrams.update( { (sentence[i][1], sentence[i+1][1], sentence[i+2][1]): count+1 } )\n",
    "    # считаем биграммы\n",
    "    for i in range(len(sentence)-1):\n",
    "        count = bigrams.get( (sentence[i][1], sentence[i+1][1]), 0)\n",
    "        bigrams.update( { (sentence[i][1], sentence[i+1][1]): count+1 } )\n",
    "    # считаем униграммы\n",
    "    for i in range(len(sentence)):\n",
    "        count = unigrams.get( (sentence[i][1]), 0)\n",
    "        unigrams.update( { (sentence[i][1]): count+1 } )\n",
    "        count = tagWords.get( (sentence[i][1], sentence[i][0]), 0)\n",
    "        tagWords.update( { (sentence[i][1], sentence[i][0]): count+1 } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(unigrams.keys())# уникальные теги\n",
    "tags.remove('*')\n",
    "tags.remove('STOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(s, u, v):\n",
    "    eps = 1e-7\n",
    "    return trigrams.get((u, v, s), eps) / bigrams.get((u, v), eps)\n",
    "\n",
    "\n",
    "def e(x, s):\n",
    "    eps = 1e-7\n",
    "    return tagWords.get((s, x), eps) / unigrams.get((s), eps)\n",
    "\n",
    "\n",
    "def getTags(n): # в начале предложения - *, * \n",
    "    if n == -1 or n == 0:\n",
    "        return ['*']\n",
    "    else:\n",
    "        return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(sentence):\n",
    "    pi = {(0, '*', '*'): 1}\n",
    "    backpointers = {}\n",
    "    n = len(sentence) - 2\n",
    "    y = [\"\"] * (n + 1)\n",
    "    \n",
    "    for k in range(1, n + 1):\n",
    "        word = sentence[k]\n",
    "        for u in getTags(k-1):\n",
    "            for v in getTags(k):\n",
    "                # находим вероятности для каждой цепочки длины k для всех пар тегов (u, v)\n",
    "                w = getTags(k-2)\n",
    "                piTemp = list(map(lambda wi:\n",
    "                            pi.get((k-1, wi, u)) *\n",
    "                            q(v, wi, u) *\n",
    "                            e(word, v), w))\n",
    "                piMax = max(piTemp)\n",
    "                bp = w[piTemp.index(piMax)]\n",
    "                pi.update({(k, u, v): piMax})\n",
    "                backpointers.update({(k, u, v): bp})\n",
    "    # вероятности всех цепочек длины n - 2 для всех пар тегов (u, v)\n",
    "    ends = {}\n",
    "    for u in getTags(n-1):\n",
    "        for v in getTags(n):\n",
    "            ends.update({(n, u, v): pi.get((n, u, v)) * q(\"STOP\", u, v)})\n",
    "    # нахождение двух последник тегов\n",
    "    endMax = max(list(ends.values()))\n",
    "    for (n, u, v), val in ends.items():\n",
    "        if val == endMax:\n",
    "            (y[n-1], y[n]) = (u,v)\n",
    "    # восстановление ответа\n",
    "    for k in range(n-2, 0, -1):\n",
    "        y[k] = backpointers.get((k + 2, y[k+1], y[k+2]))\n",
    "    return y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = conllu.parse_incr(open(\"pt_gsd-ud-test.conllu\",'r',encoding = \"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tags = [] # теги корпуса\n",
    "predict_tags = [] # теги, предсказанные алгоритмом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokenlist in data_test:\n",
    "    # получаем предложение\n",
    "    sentence=[\"*\"] + [tokenlist[i][\"lemma\"] for i in range(len(tokenlist)) ] + [\"STOP\"]\n",
    "    # получаем оригинальные теги\n",
    "    test_tags.append([tokenlist[i][\"upostag\"] for i in range(len(tokenlist)) ])\n",
    "    # получаем предсказанные таги\n",
    "    predict_tags.append(viterbi(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error =  0.29640079044549783\n"
     ]
    }
   ],
   "source": [
    "err = 0.\n",
    "for tag in range(len(test_tags)):\n",
    "    err += np.mean(np.array(test_tags[tag]) != np.array(predict_tags[tag]))\n",
    "print('Error = ', err/len(test_tags))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
